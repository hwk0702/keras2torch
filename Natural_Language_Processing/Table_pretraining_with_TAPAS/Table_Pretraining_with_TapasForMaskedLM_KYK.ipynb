{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b321e96-19ff-4470-9b22-f156e2af2210",
   "metadata": {},
   "source": [
    "# Table Pre-training with `TapasForMaskedLM`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fd9857-1b30-414b-96ee-f4d267336a2a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Author**: [Yookyung Kho](https://github.com/yookyungkho)\n",
    "\n",
    "**Date presented**: 2022/07/25, DSBA keras2torch Study\n",
    "\n",
    "**Task description**: Table-aware Masked Language Model\n",
    "\n",
    "   - Pre-Training Bert-based Tapas Model with KorWikiTabular dataset for Korean Table MRC(ex. QA)\n",
    "\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://huggingface.co/docs/transformers/model_doc/tapas\n",
    "\n",
    "- https://github.com/huggingface/transformers/blob/v4.11.3/src/transformers/models/tapas/tokenization_tapas.py\n",
    "\n",
    "- https://github.com/huggingface/transformers/blob/v4.11.3/src/transformers/data/data_collator.py\n",
    "\n",
    "- https://github.com/hwk0702/keras2torch/blob/main/Natural_Language_Processing/Question_Answering_Huggingface/QA_huggingface_KYK.ipynb\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b8693-db19-4284-a902-0802fc860387",
   "metadata": {},
   "source": [
    "## ğŸ“œPrerequisite: About Table QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d216b32-e543-4889-8527-7bb0fe566e56",
   "metadata": {},
   "source": [
    "<img src=\"imgs/table_qa_in_tapas.PNG\" width=\"900\" height=\"600\">\n",
    "\n",
    "Table Question Answeringì´ë€, ì£¼ì–´ì§„ query(ì§ˆë¬¸)ì— ëŒ€í•œ ì •ë‹µì„ ì§ˆë¬¸ê³¼ ë§¤í•‘ë˜ì–´ ìˆëŠ” tableì—ì„œ ì°¾ì•„ë‚´ëŠ” taskë¥¼ ì¼ì»«ìŠµë‹ˆë‹¤.\n",
    "\n",
    "Table QAë¥¼ ì˜ í’€ê¸° ìœ„í•´ì„œëŠ” textì™€ tableì˜ ì •ë³´ë¥¼ ì˜ í•¨ì¶•í•œ joint representationì„ í•™ìŠµí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë¥¼ ìœ„í•´ì„œ ì•„ë˜ì™€ ê°™ì´ Downstream taskì¸ Table QAë¥¼ í’€ê¸° ì´ì „ì— ëŒ€ëŸ‰ì˜ table-text ë°ì´í„°ë¥¼ ê°€ì§€ê³  ì‚¬ì „í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "<img src=\"imgs/tapas_pretraining.PNG\" width=\"900\" height=\"500\">\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "ê¸°ì¡´ table ì—°êµ¬ íë¦„ì„ ì‚´í´ë³´ë©´, ëŒ€í‘œì ìœ¼ë¡œ google researchì—ì„œ tableì„ textì™€ í•¨ê»˜ ì¸ì½”ë”©í•˜ëŠ” ë°©ì‹ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì—°êµ¬ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ ë‹¤ë£¨ê²Œ ë  ëª¨ë¸ì¸ Tapas ì—­ì‹œ googleì—ì„œ ë°œí‘œí•œ êµ¬ì¡°ì…ë‹ˆë‹¤. ([paper](https://arxiv.org/pdf/2004.02349), [github](https://github.com/google-research/tapas))\n",
    "\n",
    "googleì€ ìì‚¬ì˜ github í˜ì´ì§€ì— tensorflowë¡œ êµ¬í˜„ëœ ì½”ë“œë¥¼ ê³µê°œí•˜ì—¬ pytorch ìœ ì €ì˜ ì…ì¥ì—ì„œëŠ” í™œìš©ë„ê°€ ë†’ì§€ ì•Šì•˜ëŠ”ë°, ì–¼ë§ˆ ì „ huggingface í”Œë«í¼ì„ í†µí•´ Tapasì˜ Pytorch êµ¬í˜„ì²´ê°€ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤.(ì•¼í˜¸!ğŸ˜)\n",
    "\n",
    "ì˜¤ëŠ˜ì€ Tableì„ Textì™€ í•¨ê»˜ ì¸ì½”ë”©í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ë¡ ì„ ë‹¤ë£¨ê³  ìˆëŠ” TAPASì— ëŒ€í•´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bf953d-0d85-44f8-b7ac-d557246795f3",
   "metadata": {},
   "source": [
    "### ğŸ“¦Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed8526-49ab-4e3c-82c6-bf3644141049",
   "metadata": {},
   "source": [
    "2022ë…„ ë“œë””ì–´! LG AI Researchì—ì„œ í•œêµ­ì–´ ë²„ì „ì˜ Table MRC ë°ì´í„°ì…‹ì„ ê³µê°œí•˜ì˜€ìŠµë‹ˆë‹¤!\n",
    "\n",
    "ë°ì´í„°ì…‹ê³¼ í•¨ê»˜ ê³µê°œí•œ paperëŠ” LREC 2022ì— acceptë˜ì—ˆìŠµë‹ˆë‹¤.([Full paper ë³´ëŸ¬ ê°€ê¸°](https://arxiv.org/abs/2201.06223))\n",
    "\n",
    "<img src=\"imgs/table_mrc.PNG\" width=\"900\" height=\"450\">\n",
    "\n",
    "ê³µê°œëœ ë°ì´í„°ì…‹ì€ Pre-training(ì‚¬ì „í•™ìŠµ)ìš© ë°ì´í„°ì¸ `KorWikiTabular`ê³¼ Fine-tuning(QA)ìš© ë°ì´í„° `KorWikiTQ`, ì´ë ‡ê²Œ 2ê°€ì§€ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "- ì°¸ê³ ë¡œ, ë°ì´í„°ëŠ” [LG AI Research Github](https://github.com/LG-NLP)ì˜ [KorWikiTableQuestions Repository](https://github.com/LG-NLP/KorWikiTableQuestions)ì—ì„œ ë‹¤ìš´ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54413f48-8e8a-4657-b2db-de92968ef627",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7a46f-af20-4af3-9ad9-78a460f752bd",
   "metadata": {},
   "source": [
    "## 0. ì¤€ë¹„ ê³¼ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ce089-870c-4f62-9620-40b24581497e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 0.1. ë°ì´í„° ìƒ˜í”Œë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e42c779-2bfc-4c57-8cb0-e8af3cc8e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"data/KorWikiTabular.json\"\n",
    "\n",
    "with open(file_path, 'r', encoding=\"UTF-8\") as f:\n",
    "    tables = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0af543c-b05c-4547-8f66-ad36acaf20d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1196306"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tables['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a76d7a-9f15-40af-9288-86e9a0417bf2",
   "metadata": {},
   "source": [
    "ì•ì„œ ì†Œê°œí•œ í•œêµ­ì–´ table ì‚¬ì „í•™ìŠµ ë°ì´í„°(`KorWikiTabular`)ëŠ” ë¬´ë ¤ ì•½ **120ë§Œ ê°œ**ì˜ ìƒ˜í”Œì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.ğŸ˜±\n",
    "\n",
    "ë”°ë¼ì„œ, ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì§€ê³  ëª¨ë¸ë§ì„ ì§„í–‰í•˜ê¸°ì—ëŠ” ë¬´ë¦¬ê°€ ìˆì–´ ë³´ì…ë‹ˆë‹¤.(_GPU ë©”ëª¨ë¦¬ë„ ë¶€ì¡±í•  ë¿ë”ëŸ¬, ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¬ê² ì£ ?_)\n",
    "\n",
    "ì›í™œí•œ ì‹¤í—˜ì„ ìœ„í•´ **200ê°œì˜ ìƒ˜í”Œë§Œ ëœë¤ìœ¼ë¡œ ì¶”ì¶œ**í•˜ì—¬ `sample_200_KorWikiTabular.json`ì˜ í˜•íƒœë¡œ `data` ê²½ë¡œì— ì €ì¥í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae966c8-3860-4adf-a5f4-22f2fafc33f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(602)\n",
    "\n",
    "randn_idxs = np.random.choice(list(range(len(tables['data']))), size=200, replace=False) #ë¹„ë³µì›ì¶”ì¶œ\n",
    "\n",
    "sample_tables = {'data': []}\n",
    "\n",
    "for new_id, org_id in enumerate(randn_idxs):\n",
    "    sample_tables['data'].append(tables['data'][org_id])\n",
    "    sample_tables['data'][new_id]['org_idx'] = int(org_id)\n",
    "    \n",
    "file_path = \"data/sample_200_KorWikiTabular.json\"\n",
    "json.dump(sample_tables, open(file_path,'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffecaa7-d121-401f-839d-8b90a3540fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_tables['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ab71d-9b3c-4bd1-995a-aa778fd64bb4",
   "metadata": {},
   "source": [
    "ì €ì¥ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "ì•ìœ¼ë¡œëŠ” ìœ„ 4ê°œ cell ì‹¤í–‰ ì—†ì´, sample dataë§Œ ë°”ë¡œ ë¶ˆëŸ¬ë“¤ì—¬ì™€ì„œ ì‹¤í—˜ ì§„í–‰í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb48b5d3-6928-4b04-b333-bbe8715cb8be",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe3839b-d860-43e3-858d-d8e82beff4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"data/sample_200_KorWikiTabular.json\"\n",
    "\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    sample_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e40c00-0b46-4d55-95a6-dce022773037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_data['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906d161-595e-489c-9670-46c21d0256e6",
   "metadata": {},
   "source": [
    "### 0.2. Module Import, GPU ì„¸íŒ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a24e7-499d-49a6-b5a7-64c730f96b1f",
   "metadata": {},
   "source": [
    "ì§€ê¸ˆì²˜ëŸ¼ ì†ŒëŸ‰(200ê°œ)ì˜ ìƒ˜í”Œ ë°ì´í„°ë§Œ ë½‘ì•„ ì“°ëŠ” ê²½ìš°ê°€ ì•„ë‹ˆë¼ Full datasetì„ ëª¨ë‘ ëŒë¦´ ë•Œì—ëŠ”, local gpuë§Œìœ¼ë¡œ MLM í•™ìŠµì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.(ì´ìœ : ë©”ëª¨ë¦¬ ë¶€ì¡±)\n",
    "\n",
    "ë”°ë¼ì„œ, multi-gpuë¥¼ ì¥ì°©í•œ ì„œë²„ í™˜ê²½ì—ì„œ ëŒë ¤ì•¼ í•˜ëŠ”ë°, ì´ ê²½ìš°ì— í•„ìš”í•œ ì½”ë“œë„ í•¨ê»˜ ì ì–´ë‘ì—ˆìœ¼ë‹ˆ ì°¸ê³ í•´ì£¼ì„¸ìš”!\n",
    "\n",
    "\n",
    "\n",
    "> ğŸ’™Requirements\n",
    "> \n",
    "> - `torch == 1.12.0+cu113`\n",
    "> - `torch-scatter == 2.0.9`(for `TapasModel`)\n",
    "> - `transformers == 4.11.3`\n",
    "> - `pandas == 1.3.5`\n",
    "\n",
    "- ì´ ì¤‘ `torch-scatter` ì„¤ì¹˜ ê´€ë ¨í•´ì„œëŠ” [ì´ link](https://github.com/rusty1s/pytorch_scatter)ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb95a402-8324-4362-9b6f-09c15b01e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import argparse\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import TapasConfig, TapasTokenizer, TapasForMaskedLM, AdamW, get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7c4aed-a5ac-4491-8caa-1d8acd59ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi gpu\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1,2,3\"  # Set the GPUs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba2a7cb-0460-425f-ba62-903f461bfae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--vocab_model_name\", default=\"klue/bert-base\", type=str)\n",
    "parser.add_argument(\"--tok_path\", default=\"table_tokenizer\", type=str)\n",
    "\n",
    "parser.add_argument(\"--max_seq_len\", default=512, type=int)\n",
    "parser.add_argument(\"--max_query_len\", default=470, type=int)\n",
    "parser.add_argument(\"--row_del_ratio\", default=0.9, type=float)\n",
    "parser.add_argument(\"--col_del_ratio\", default=0.9, type=float)\n",
    "parser.add_argument(\"--mlm_prob\", default=0.15, type=float)\n",
    "\n",
    "parser.add_argument(\"--random_seed\", default=602, type=int)\n",
    "\n",
    "parser.add_argument(\"--epoch\", default=5, type=int)\n",
    "parser.add_argument(\"--batch_size\", default=16, type=int)\n",
    "parser.add_argument(\"--learning_rate\", default=4e-4, type=float)\n",
    "parser.add_argument(\"--weight_decay\", default=0.0, type=float)\n",
    "parser.add_argument(\"--lr_scheduler_type\", default=\"linear\", type=str)\n",
    "parser.add_argument(\"--num_warmup_steps\", default=0, type=int)\n",
    "parser.add_argument(\"--eval_step\", default=10, type=int)\n",
    "\n",
    "parser.add_argument(\"--wandb_project\", default=\"Table Pretraining\", type=str)\n",
    "parser.add_argument(\"--wandb_name\", default=\"tapas-base-mlm-clean\", type=str)\n",
    "parser.add_argument(\"--wandb_entity\", default=\"yookyungkho\", type=str)\n",
    "\n",
    "parser.add_argument(\"--output_dir\", default=\"models/\", type=str)\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3a2e46-87ec-4e1c-908f-7cd4ee62ac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 4\n",
      "number of gpu:  4\n"
     ]
    }
   ],
   "source": [
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #multi_gpu\n",
    "\n",
    "print('Device:', args.device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(\"number of gpu: \", n_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfee8cb-c4ab-4af2-854d-7a6bb9d176cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed ê³ ì •\n",
    "def seed_everything(seed):\n",
    "    # random.seed(seed) #masking dynamicsë¥¼ ìœ„í•´ ì´ ë¶€ë¶„ì€ ì£¼ì„ ì²˜ë¦¬\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "\n",
    "seed_everything(args.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d539b39-60f4-4624-88fc-8e66a3599294",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ì´ì œ ëª¨ë¸ë§ì„ ìœ„í•œ ì¤€ë¹„ë¥¼ ë§ˆì³¤ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì§€ê¸ˆë¶€í„°ëŠ” ë³¸ê²©ì ìœ¼ë¡œ ì‚¬ì „í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ì„ ì „ì²˜ë¦¬í•˜ê³  ëª¨ë¸ì„ êµ¬ì¶•í•œ ë’¤, ì‹¤ì œ í•™ìŠµì„ ì§„í–‰í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë ›ì¸ ê³µ~ğŸ’›\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7e7d14-d379-4e9b-ad94-974ef27032a8",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a4e518-74ef-4ade-b1f6-e20a68a372d2",
   "metadata": {},
   "source": [
    "Tapasì˜ ì‚¬ì „í•™ìŠµ taskëŠ” Table-aware Masked Language Modelì…ë‹ˆë‹¤.\n",
    "\n",
    "textì™€ tableì„ inputìœ¼ë¡œ ë°›ì•„ í•˜ë‚˜ì˜ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•˜ê³ , ì‹œí€€ìŠ¤ ë‚´ íŠ¹ì • ë¹„ìœ¨(ex. 15%)ì˜ í† í°ì— ì´ 2ê°€ì§€ ë°©ì‹ì˜ maskingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "<img src=\"imgs/tapas_masking.png\" width=\"1000\" height=\"600\">\n",
    "\n",
    "\n",
    "1. **Whole Word Masking**: ëœë¤ìœ¼ë¡œ ì„ íƒëœ ë‹¨ì–´ì˜ ëª¨ë“  í† í°ì„ masking\n",
    "\n",
    "2. **Whole Cell Masking**: ëœë¤ìœ¼ë¡œ ì„ íƒëœ table cellì˜ ëª¨ë“  í† í°ì„ masking\n",
    "\n",
    "<br/>\n",
    "\n",
    "ì´ë ‡ê²Œ 2ê°€ì§€ ë°©ì‹ì˜ maskingì„ í†µí•´ ìœ„ ê·¸ë¦¼ê³¼ ê°™ì€ Table MLMì˜ inputì„ ìƒì„±í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì§€ê¸ˆë¶€í„° í•œë‹¨ê³„ì”© input í˜•íƒœë¥¼ ê°–ì¶°ê°€ëŠ” ê³¼ì •ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284505cf-1611-4f4d-bcab-1bba5ee5498d",
   "metadata": {},
   "source": [
    "### 1.1. `TableTokenizer` ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95006c93-06ae-4542-a4d0-3ef40841bbe2",
   "metadata": {},
   "source": [
    "ìš°ì„ , table ì „ìš© í† í¬ë‚˜ì´ì €ì¸ `TapasTokenizer`ë¶€í„° ë¶ˆëŸ¬ì˜¤ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f767fd11-b0c8-48c8-a6a8-b2a63861bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TapasTokenizer\n",
    "\n",
    "tapas_tokenizer = TapasTokenizer.from_pretrained(args.vocab_model_name)\n",
    "tapas_tokenizer.save_pretrained(args.tok_path)\n",
    "\n",
    "tokenizer = TapasTokenizer.from_pretrained(args.tok_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae13a98-9d79-43c0-aaf8-037e406f07a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['[PAD]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d56003d-74d3-4fed-9e57-36d817079f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer) #vocab íŒŒì¼ì— ëª…ì‹œë˜ì–´ìˆì§€ëŠ” ì•Šì§€ë§Œ special tokenìœ¼ë¡œëŠ” í¬í•¨ë˜ì–´ ìˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd926fa2-9a1c-4249-9083-749761cfb84c",
   "metadata": {},
   "source": [
    "\n",
    "ìš°ë¦¬ëŠ” ì´ `TapasTokenizer`ë¥¼ ê·¸ëŒ€ë¡œ ì“°ì§€ ì•Šê³ , Table-aware MLM í•™ìŠµì— ë§ê²Œ ë³€í˜•í•´ì„œ í™œìš©í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë¥¼ ìœ„í•´, `TapasTokenizer` classë¥¼ ìƒì†ë°›ì•„ í•„ìš”í•œ methodë¥¼ ì§ì ‘ ì •ì˜í•˜ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ì²˜ëŸ¼ ë§ì´ì£ !\n",
    "\n",
    "> **â£ ì£¼ì˜ â£**\n",
    "> \n",
    "> _transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë²„ì „ì„ ê¼­ í™•ì¸í•˜ì„¸ìš”!! ë²„ì „ ë§ˆë‹¤ êµ¬í˜„ì²´ê°€ ì¡°ê¸ˆì”© ë‹¤ë¥´ê¸° ë•Œë¬¸ì—, ì„¤ì¹˜ëœ ë²„ì „ê³¼ ë‹¤ë¥¸ ë²„ì „ì—ì„œ ì •ì˜ëœ ë³€ìˆ˜ë‚˜ ë©”ì†Œë“œë¥¼ ë¶ˆëŸ¬ì˜¬ ì‹œ ì—ëŸ¬ê°€ ë°œìƒí•˜ê²Œ ë©ë‹ˆë‹¤! í˜„ì¬ ì„¤ì¹˜ë˜ì–´ ìˆëŠ” ë²„ì „ì— ë§ëŠ” ì†ŒìŠ¤ì½”ë“œë¥¼ ì°¸ê³ í•˜ì„¸ìš”! ì°¸ê³ ë¡œ ì œê°€ ì‚¬ìš©í•œ ë²„ì „ì€ `transformers==4.11.3` ì…ë‹ˆë‹¤._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e12b882-f7f3-4d6b-a46b-57a56846b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenizer_utils.pyì— ìœ„ì¹˜í•  ê²ƒ\n",
    "\n",
    "def create_token_word_idx_list(word_list):\n",
    "    # token ë³„ë¡œ ëª‡ë²ˆì§¸ wordì— ì†í•´ìˆëŠ”ì§€ íŒŒì•…í•˜ê¸° ìœ„í•œ index ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "    n = 0\n",
    "    word_idx = []\n",
    "    for r in range(len(word_list)):\n",
    "        toks = tokenizer.tokenize(word_list[r])\n",
    "        idxs = []\n",
    "        for _ in range(len(toks)):\n",
    "            n += 1\n",
    "            idxs.append(n)\n",
    "        word_idx.append(idxs)\n",
    "\n",
    "    assert len(word_idx) == len(word_list)\n",
    "    \n",
    "    return word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "759cd87f-7aee-46ac-a498-38841fa0c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableTokenizer(TapasTokenizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        \n",
    "    def query_truncate(self, query, max_query_len):\n",
    "        \"\"\"\n",
    "        TapasTokenizerì—ëŠ” max_query_lenì— ë§ê²Œ queryë¥¼ truncateí•˜ëŠ” ê¸°ëŠ¥ì´ ì—†ìŠµë‹ˆë‹¤.\n",
    "        query tokenì˜ ê¸¸ì´ê°€ max_query_lenì„ ë„˜ê²¼ì„ ë•Œë‚˜, min_query_lenë³´ë‹¤ ì§§ì„ ë•Œ,\n",
    "        queryë¥¼ ì¸ì½”ë”©í•˜ì§€ ì•Šê³  ì „ë¶€ ë²„ë¦½ë‹ˆë‹¤.(ì•„ë˜ ì½”ë“œì²˜ëŸ¼)\n",
    "            \n",
    "            def _get_question_tokens(self, query):\n",
    "                # Tokenizes the query, taking into account the max and min question length.\n",
    "                query_tokens = self.tokenize(query)\n",
    "                if self.max_question_length is not None and len(query_tokens) > self.max_question_length:\n",
    "                    logger.warning(\"Skipping query as its tokens are longer than the max question length\")\n",
    "                    return \"\", []\n",
    "                if self.min_question_length is not None and len(query_tokens) < self.min_question_length:\n",
    "                    logger.warning(\"Skipping query as its tokens are shorter than the min question length\")\n",
    "                    return \"\", []\n",
    "\n",
    "                return query, query_tokens\n",
    "        \n",
    "        ì™œ ì „ë¶€ ë²„ë ¤ì•¼ í•˜ì£ ? ì¡°ê¸ˆì€ ë‚¨ê¸¸ ìˆ˜ ìˆëŠ” ê±°ì–ì•„ìš”?\n",
    "        ê·¸ë˜ì„œ query_truncate ë©”ì†Œë“œë¥¼ ìƒˆë¡œ ì •ì˜í•´ë³´ì•˜ìŠµë‹ˆë‹¤.\n",
    "        êµ¬í˜„ ë°©ì‹ì—ì„œ ë” ì¢‹ì€ ì•„ì´ë””ì–´ê°€ ìˆë‹¤ë©´ í†¡~íˆ¬~ë¯¸~\n",
    "        \"\"\"\n",
    "        query_tokens = self.tokenize(query)\n",
    "        \n",
    "        if len(query_tokens) > max_query_len:\n",
    "            query_words = query.split()\n",
    "            query_word_idx = create_token_word_idx_list(query_words)\n",
    "            for i, query_tokens in enumerate(query_word_idx):\n",
    "                if max_query_len in query_tokens:\n",
    "                    end_word_idx = i\n",
    "            \n",
    "            query_txt = \" \".join(query_words[:end_word_idx])\n",
    "        \n",
    "            return query_txt\n",
    "            \n",
    "            ### table ê¸¸ì´ë„ ê³ ë ¤í•´ì„œ max query len ìë™ ì§€ì •í•˜ëŠ” ë°©ì•ˆë„ ê´œì°®ì„ê±°ê°™ì•„ìš”~(ë‚˜ì¤‘ì—)\n",
    "        else:\n",
    "            return query\n",
    "        \n",
    "        \n",
    "    def get_idx_features_for_masking(self, table, query, max_length = 512):\n",
    "        # 1) table ê° cellì˜ ì¢Œí‘œ ì •ë³´ë¥¼ ë¹„ë¡¯í•˜ì—¬ query, tableì„ ê°ê° ì¸ì½”ë”©í•œ ê²°ê³¼ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.\n",
    "        table_data, query_ids, table_ids = self.get_coordinates(table, query, max_length)\n",
    "        \n",
    "        # 2) queryì™€ tableì´ ëª‡ê°œì˜ í† í°ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ì§€ ì‹œí€€ìŠ¤ ê¸¸ì´ ì •ë³´ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.\n",
    "        len_query, len_table = self.get_length_before_pad(query_ids, table_ids)\n",
    "        len_info = [len_query, len_table]\n",
    "        \n",
    "        # 3) whole word masking(text)ì„ ìœ„í•´ ë‹¨ì–´ ë³„ í† í°ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.\n",
    "        whole_word_idxs = self.get_whole_word_info(query_ids)\n",
    "        \n",
    "        # 4) whole cell masking(table)ì„ ìœ„í•´ cell ë³„ í† í°ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.\n",
    "        whole_cell_idxs = self.get_whole_cell_info(len_query, table_data)\n",
    "        \n",
    "        whole_word_idxs.extend(whole_cell_idxs)\n",
    "        # print(whole_word_idxs, len_info)\n",
    "        \n",
    "        return whole_word_idxs, len_info, query_ids, table_ids\n",
    "            \n",
    "    # 1) table ê° cellì˜ ì¢Œí‘œ ì •ë³´ë¥¼ ë¹„ë¡¯í•˜ì—¬ query, tableì„ ê°ê° ì¸ì½”ë”©í•œ ê²°ê³¼ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.\n",
    "    def get_coordinates(self, table, query, max_length = 512, truncation=\"drop_rows_to_fit\"):\n",
    "        ## truncation : DROP_ROWS_TO_FIT = \"drop_rows_to_fit\",  DO_NOT_TRUNCATE = \"do_not_truncate\"\n",
    "        \n",
    "        ## https://github.com/huggingface/transformers/blob/v4.11.3/src/transformers/models/tapas/tokenization_tapas.py#L1039\n",
    "        table_tokens = self._tokenize_table(table)\n",
    "        query_tokens = self.tokenize(query) # query, query_tokens = self._get_question_tokens(query) #(4.xx.x ë²„ì „)\n",
    "        \n",
    "        ## https://github.com/huggingface/transformers/blob/v4.11.3/src/transformers/models/tapas/tokenization_tapas.py#L1138\n",
    "        num_rows = self._get_num_rows(table, truncation != \"do_not_truncate\") #row idxëŠ” 0ë¶€í„° ì‹œì‘\n",
    "        num_columns = self._get_num_columns(table) #col idxëŠ” 1ë¶€í„° ì‹œì‘\n",
    "        _, _, num_tokens = self._get_table_boundaries(table_tokens)\n",
    "\n",
    "        if truncation != \"do_not_truncate\":\n",
    "            num_rows, num_tokens = self._get_truncated_table_rows(\n",
    "                query_tokens, table_tokens, num_rows, num_columns, max_length, truncation_strategy=truncation\n",
    "            )\n",
    "        \n",
    "        table_data = list(self._get_table_values(table_tokens, num_columns, num_rows, num_tokens))\n",
    "        # [TokenValue(token='ì¸µ', column_id=1, row_id=0),\n",
    "        #  TokenValue(token='##ìˆ˜', column_id=1, row_id=0),\n",
    "        #  TokenValue(token='ì‹œì„¤', column_id=2, row_id=0),\n",
    "        #  TokenValue(token='ë¹„', column_id=3, row_id=0),\n",
    "        #  TokenValue(token='##ê³ ', column_id=3, row_id=0),\n",
    "        # ...\n",
    "        \n",
    "        query_ids = self.convert_tokens_to_ids(query_tokens)\n",
    "        \n",
    "        table_ids = list(zip(*table_data))[0] if len(table_data) > 0 else list(zip(*table_data))\n",
    "        table_ids = self.convert_tokens_to_ids(list(table_ids))\n",
    "    \n",
    "        return table_data, query_ids, table_ids\n",
    "    \n",
    "    \n",
    "    # 2) queryì™€ tableì´ ëª‡ê°œì˜ í† í°ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ì§€ ì‹œí€€ìŠ¤ ê¸¸ì´ ì •ë³´ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.\n",
    "    def get_length_before_pad(self, query_data, table_data):\n",
    "        return len(query_data), len(table_data)\n",
    "        \n",
    "        \n",
    "    # 3) whole word masking(text)ì„ ìœ„í•´ ë‹¨ì–´ ë³„ í† í°ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.\n",
    "    def get_whole_word_info(self, query_ids):\n",
    "        '''whole word index information for text masking'''\n",
    "        ref_tokens = []\n",
    "        for n, token_idx in enumerate(query_ids):\n",
    "            token = tokenizer._convert_id_to_token(token_idx)\n",
    "            ref_tokens.append(token)\n",
    "            \n",
    "        cand_indexes = []\n",
    "        for (i, token) in enumerate(ref_tokens):\n",
    "            if len(cand_indexes) >= 1 and token.startswith(\"##\"):\n",
    "                cand_indexes[-1].append(i+1)\n",
    "            else:\n",
    "                cand_indexes.append([i+1])\n",
    "        \n",
    "        return cand_indexes\n",
    "    \n",
    "    \n",
    "    # 4) whole cell masking(table)ì„ ìœ„í•´ cell ë³„ í† í°ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.\n",
    "    def get_whole_cell_info(self, len_query, table_cell_info):\n",
    "        '''whole cell index information fir table masking'''\n",
    "        idx_order = len_query + 2\n",
    "        total_cell_cands, one_cell = [], []\n",
    "        start_row = 0\n",
    "        start_col = 1\n",
    "        \n",
    "        for tok_idx, tok_info in enumerate(table_cell_info):\n",
    "            if tok_idx == len(table_cell_info) - 1:\n",
    "                one_cell.append(idx_order+tok_idx)\n",
    "                total_cell_cands.append(one_cell)\n",
    "            else:\n",
    "                if tok_info.row_id == start_row:\n",
    "                    if tok_info.column_id == start_col:\n",
    "                        one_cell.append(idx_order+tok_idx)\n",
    "                    else:\n",
    "                        total_cell_cands.append(one_cell)\n",
    "                        one_cell = []\n",
    "                        start_col += 1\n",
    "                        one_cell.append(idx_order+tok_idx)\n",
    "                else:\n",
    "                    total_cell_cands.append(one_cell)\n",
    "                    one_cell = []\n",
    "                    start_row += 1\n",
    "                    start_col = 1\n",
    "                    one_cell.append(idx_order+tok_idx)\n",
    "        \n",
    "        return total_cell_cands\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af7661-dff3-443d-8668-5d724223ac5f",
   "metadata": {},
   "source": [
    "ìƒˆë¡­ê²Œ ì •ì˜ëœ TableTokenizerê°€ ì–´ë–¤ ì‹ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ ì•„ë˜ ì˜ˆì‹œë¥¼ í†µí•´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3e212e1-54b9-4a46-80ab-d46041058dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'TapasTokenizer'. \n",
      "The class this function is called from is 'TableTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TableTokenizer.from_pretrained(args.tok_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c9487b-534e-4f34-88dc-3d2126866896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nì„œìš¸íƒ€ì›Œì˜ ì¸µìˆ˜ëŠ” P0, P1, P2, EZ, T1, T2, T3, T5ë¡œ ì´ 8ê°œ ì¸µìœ¼ë¡œ ë˜ì–´ìˆë‹¤. PëŠ” í”Œë¼ìì˜ ì•½ìì´ë©° ì¶œì…êµ¬ì™€ ì•½ê°„ì˜ ìƒê°€ë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. EZëŠ” ìµìŠ¤í”„ë ˆìŠ¤ ì¡´ì˜ ì•½ìì´ë©° í°ìƒ‰ ê¸°ë‘¥ë¶€ë¶„ì„ ê°€ë¦¬í‚¨ë‹¤. TëŠ” íƒ€ì›Œì˜ ì•½ìì´ë©° ì „ë§ëŒ€ì™€ ìŠ¤ë‚µì½”ë„ˆ, ê·¸ë¦¬ê³  ì‹ë‹¹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì§€í•˜ 1ì¸µì—ì„œ ì§€ìƒ 5ì¸µê¹Œì§€ëŠ” ì„œìš¸íƒ€ì›Œ í”Œë¼ìì˜ ì‹œì„¤ì´ ìˆê³  5ì¸µë¶€í„° íƒ€ì›Œ 1ì¸µì—ì„œ íƒ€ì›Œ 5ì¸µê¹Œì§€ëŠ” Nì„œìš¸íƒ€ì›Œì˜ ì‹œì„¤ì´ ìˆë‹¤. ë‚¨ì‚° ì¼€ì´ë¸”ì¹´ë„ ìœ ëª…í•˜ë‹¤.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_text = \"Nì„œìš¸íƒ€ì›Œì˜ ì¸µìˆ˜ëŠ” P0, P1, P2, EZ, T1, T2, T3, T5ë¡œ ì´ 8ê°œ ì¸µìœ¼ë¡œ ë˜ì–´ìˆë‹¤. PëŠ” í”Œë¼ìì˜ ì•½ìì´ë©° ì¶œì…êµ¬ì™€ ì•½ê°„ì˜ ìƒê°€ë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. EZëŠ” ìµìŠ¤í”„ë ˆìŠ¤ ì¡´ì˜ ì•½ìì´ë©° í°ìƒ‰ ê¸°ë‘¥ë¶€ë¶„ì„ ê°€ë¦¬í‚¨ë‹¤. TëŠ” íƒ€ì›Œì˜ ì•½ìì´ë©° ì „ë§ëŒ€ì™€ ìŠ¤ë‚µì½”ë„ˆ, ê·¸ë¦¬ê³  ì‹ë‹¹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì§€í•˜ 1ì¸µì—ì„œ ì§€ìƒ 5ì¸µê¹Œì§€ëŠ” ì„œìš¸íƒ€ì›Œ í”Œë¼ìì˜ ì‹œì„¤ì´ ìˆê³  5ì¸µë¶€í„° íƒ€ì›Œ 1ì¸µì—ì„œ íƒ€ì›Œ 5ì¸µê¹Œì§€ëŠ” Nì„œìš¸íƒ€ì›Œì˜ ì‹œì„¤ì´ ìˆë‹¤. ë‚¨ì‚° ì¼€ì´ë¸”ì¹´ë„ ìœ ëª…í•˜ë‹¤.\"\n",
    "ex_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0367412a-1e3a-45c4-914f-959e38f50149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ì¸µìˆ˜</th>\n",
       "      <th>ì‹œì„¤</th>\n",
       "      <th>ë¹„ê³ </th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>ì—”ê·¸ë¦´/ê¸°ê³„ì‹¤</td>\n",
       "      <td>ì–‘ì‹ë‹¹ 'ì—”ê·¸ë¦´'ì´ë©° ì´ê³³ì—ì„œëŠ” ê°œì„±ê³¼ ì¸ì²œì˜ ê´€ì¸¡ë„ ê°€ëŠ¥í•˜ë‹¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>íƒ€ì›Œ 6ì¸µ</td>\n",
       "      <td>Nì¹¼êµ­ìˆ˜,ì „ë§ëŒ€</td>\n",
       "      <td>... íœ´ì „ì„ ê¹Œì§€ ê´€ì¸¡ ê°€ëŠ¥í•˜ë‹¤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>íƒ€ì›Œ 5ì¸µ</td>\n",
       "      <td>nan</td>\n",
       "      <td>ë””ì§€í„¸ ì „ë§ëŒ€ì™€ ìƒí–‰ ì—˜ë¦¬ë² ì´í„°ê°€ ìˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>íƒ€ì›Œ 4ì¸µ</td>\n",
       "      <td>ì „ë§ëŒ€, Ní¬í†  ìŠ¤íŠœë””ì˜¤, í•˜ëŠ˜ í™”ì¥ì‹¤, íˆ¬ì¸ì»¤í”¼</td>\n",
       "      <td>ì•„ë‚ ë¡œê·¸ ì „ë§ëŒ€ì™€ í•˜í–‰ ì—˜ë¦¬ë² ì´í„°ê°€ ìˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>íƒ€ì›Œ 3ì¸µ</td>\n",
       "      <td>nan</td>\n",
       "      <td>ì´ê³³ì—ì„œëŠ” ì„œìš¸ ì‹œë‚´ê¹Œì§€ë§Œ ë³´ì¸ë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>íƒ€ì›Œ 2ì¸µ</td>\n",
       "      <td>ë£¨í”„í…Œë¼ìŠ¤, ë” í”Œë ˆì´ìŠ¤ ë‹¤ì´ë‹</td>\n",
       "      <td>ë£¨í”„í…Œë¼ìŠ¤, ë” í”Œë ˆì´ìŠ¤ ë‹¤ì´ë‹ì´ ìˆë‹¤.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ì¸µìˆ˜                           ì‹œì„¤                                     ë¹„ê³ \n",
       "0    nan                      ì—”ê·¸ë¦´/ê¸°ê³„ì‹¤  ì–‘ì‹ë‹¹ 'ì—”ê·¸ë¦´'ì´ë©° ì´ê³³ì—ì„œëŠ” ê°œì„±ê³¼ ì¸ì²œì˜ ê´€ì¸¡ë„ ê°€ëŠ¥í•˜ë‹¤...\n",
       "1  íƒ€ì›Œ 6ì¸µ                     Nì¹¼êµ­ìˆ˜,ì „ë§ëŒ€                      ... íœ´ì „ì„ ê¹Œì§€ ê´€ì¸¡ ê°€ëŠ¥í•˜ë‹¤\n",
       "2  íƒ€ì›Œ 5ì¸µ                          nan                 ë””ì§€í„¸ ì „ë§ëŒ€ì™€ ìƒí–‰ ì—˜ë¦¬ë² ì´í„°ê°€ ìˆë‹¤.\n",
       "3  íƒ€ì›Œ 4ì¸µ  ì „ë§ëŒ€, Ní¬í†  ìŠ¤íŠœë””ì˜¤, í•˜ëŠ˜ í™”ì¥ì‹¤, íˆ¬ì¸ì»¤í”¼                ì•„ë‚ ë¡œê·¸ ì „ë§ëŒ€ì™€ í•˜í–‰ ì—˜ë¦¬ë² ì´í„°ê°€ ìˆë‹¤.\n",
       "4  íƒ€ì›Œ 3ì¸µ                          nan                    ì´ê³³ì—ì„œëŠ” ì„œìš¸ ì‹œë‚´ê¹Œì§€ë§Œ ë³´ì¸ë‹¤.\n",
       "5  íƒ€ì›Œ 2ì¸µ            ë£¨í”„í…Œë¼ìŠ¤, ë” í”Œë ˆì´ìŠ¤ ë‹¤ì´ë‹                 ë£¨í”„í…Œë¼ìŠ¤, ë” í”Œë ˆì´ìŠ¤ ë‹¤ì´ë‹ì´ ìˆë‹¤."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_table = [[\"ì¸µìˆ˜\", \"ì‹œì„¤\", \"ë¹„ê³ \"],\n",
    "[\"\", \"ì—”ê·¸ë¦´/ê¸°ê³„ì‹¤\", \"ì–‘ì‹ë‹¹ 'ì—”ê·¸ë¦´'ì´ë©° ì´ê³³ì—ì„œëŠ” ê°œì„±ê³¼ ì¸ì²œì˜ ê´€ì¸¡ë„ ê°€ëŠ¥í•˜ë‹¤...\"],\n",
    "[\"íƒ€ì›Œ 6ì¸µ\", \"Nì¹¼êµ­ìˆ˜,ì „ë§ëŒ€\", \"... íœ´ì „ì„ ê¹Œì§€ ê´€ì¸¡ ê°€ëŠ¥í•˜ë‹¤\"],\n",
    "[\"íƒ€ì›Œ 5ì¸µ\", \"\", \"ë””ì§€í„¸ ì „ë§ëŒ€ì™€ ìƒí–‰ ì—˜ë¦¬ë² ì´í„°ê°€ ìˆë‹¤.\"],\n",
    "[\"íƒ€ì›Œ 4ì¸µ\", \"ì „ë§ëŒ€, Ní¬í†  ìŠ¤íŠœë””ì˜¤, í•˜ëŠ˜ í™”ì¥ì‹¤, íˆ¬ì¸ì»¤í”¼\", \"ì•„ë‚ ë¡œê·¸ ì „ë§ëŒ€ì™€ í•˜í–‰ ì—˜ë¦¬ë² ì´í„°ê°€ ìˆë‹¤.\"],\n",
    "[\"íƒ€ì›Œ 3ì¸µ\", \"\", \"ì´ê³³ì—ì„œëŠ” ì„œìš¸ ì‹œë‚´ê¹Œì§€ë§Œ ë³´ì¸ë‹¤.\"],\n",
    "[\"íƒ€ì›Œ 2ì¸µ\", \"ë£¨í”„í…Œë¼ìŠ¤, ë” í”Œë ˆì´ìŠ¤ ë‹¤ì´ë‹\", \"ë£¨í”„í…Œë¼ìŠ¤, ë” í”Œë ˆì´ìŠ¤ ë‹¤ì´ë‹ì´ ìˆë‹¤.\"]]\n",
    "\n",
    "ex_tbl_df = pd.DataFrame(ex_table)\n",
    "ex_tbl_df = ex_tbl_df.rename(columns=ex_tbl_df.iloc[0])\n",
    "ex_tbl_df = ex_tbl_df.drop(ex_tbl_df.index[0])\n",
    "ex_tbl_df.reset_index(drop=True, inplace=True)\n",
    "ex_tbl_df = ex_tbl_df.astype('str')\n",
    "\n",
    "for row_index, row in ex_tbl_df.iterrows():\n",
    "    for col_index, cell in enumerate(row):\n",
    "        #print(row_index, col_index, ex_tbl_df.iloc[row_index, col_index])\n",
    "        if ex_tbl_df.iloc[row_index, col_index] == \"\":\n",
    "            ex_tbl_df.iloc[row_index, col_index] = \"nan\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "ex_tbl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04d3f254-8fa1-4735-83ed-54fa0d226130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 50, 28750, 2256, 2667, 2079, 1688, 2113, 2259, 52, 2082, 16, 52, 2083, 16, 52, 2302, 16, 41, 2611, 16, 56, 2083, 16, 56, 2302, 16, 56, 2195, 16, 56, 2049, 2200, 1668, 28, 2019, 1688, 6233, 859, 2051, 2689, 2062, 18, 52, 2259, 16597, 2079, 9383, 2052, 2307, 18455, 2522, 4943, 2079, 6682, 2200, 3896, 2496, 2051, 2689, 2062, 18, 41, 2611, 2259, 24284, 1554, 2079, 9383, 2052, 2307, 12003, 9856, 12547, 2069, 16519, 18, 56, 2259, 8203, 2079, 9383, 2052, 2307, 14822, 2522, 1, 16, 3673, 5499, 6233, 3896, 2496, 2051, 1513, 2062, 18, 4670, 21, 2624, 27135, 5377, 25, 2624, 2299, 2118, 2259, 3671, 2256, 2667, 16597, 2079, 3953, 2052, 1513, 2088, 25, 2624, 3797, 8203, 21, 2624, 27135, 8203, 25, 2624, 2299, 2118, 2259, 50, 28750, 2256, 2667, 2079, 3953, 2052, 1513, 2062, 18, 12103, 15879, 2119, 4455, 2205, 2062, 18, 3, 1688, 2113, 3953, 1187, 2088, 32000, 1423, 2029, 2388, 19, 5276, 2477, 6277, 2481, 11, 1423, 2029, 2388, 11, 1504, 2307, 4441, 27135, 2259, 5879, 2145, 4068, 2079, 6541, 2119, 3662, 2205, 2062, 18, 18, 18, 8203, 26, 2624, 50, 2600, 9473, 16, 14822, 18, 18, 18, 31099, 2299, 2118, 6541, 3662, 2205, 2062, 8203, 25, 2624, 32000, 5476, 14822, 2522, 1242, 2375, 10874, 2116, 1513, 2062, 18, 8203, 24, 2624, 14822, 16, 50, 2208, 2386, 9238, 16, 4573, 7047, 16, 1801, 3428, 20468, 16834, 14822, 2522, 1889, 2375, 10874, 2116, 1513, 2062, 18, 8203, 23, 2624, 32000, 4441, 27135, 2259, 3671, 6011, 2299, 3683, 4090, 18, 8203, 22, 2624, 19283, 2201, 5822, 16, 831, 18312, 5970, 2944, 19283, 2201, 5822, 16, 831, 18312, 5970, 2944, 2052, 1513, 2062, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0], [1, 2, 0, 0, 0, 0, 0], [1, 3, 0, 0, 0, 0, 0], [1, 3, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 0], [1, 2, 1, 0, 0, 0, 0], [1, 2, 1, 0, 0, 0, 0], [1, 2, 1, 0, 0, 0, 0], [1, 2, 1, 0, 0, 0, 0], [1, 2, 1, 0, 0, 0, 0], [1, 2, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 3, 1, 0, 0, 0, 0], [1, 1, 2, 0, 5, 1, 6], [1, 1, 2, 0, 5, 1, 6], [1, 1, 2, 0, 5, 1, 6], [1, 2, 2, 0, 0, 0, 0], [1, 2, 2, 0, 0, 0, 0], [1, 2, 2, 0, 0, 0, 0], [1, 2, 2, 0, 0, 0, 0], [1, 2, 2, 0, 0, 0, 0], [1, 3, 2, 0, 0, 0, 0], [1, 3, 2, 0, 0, 0, 0], [1, 3, 2, 0, 0, 0, 0], [1, 3, 2, 0, 0, 0, 0], [1, 3, 2, 0, 0, 0, 0], [1, 3, 2, 0, 0, 0, 0], [1, 3, 2, 0, 0, 0, 0], [1, 3, 2, 0, 0, 0, 0], [1, 3, 2, 0, 0, 0, 0], [1, 3, 2, 0, 0, 0, 0], [1, 1, 3, 0, 4, 2, 7], [1, 1, 3, 0, 4, 2, 7], [1, 1, 3, 0, 4, 2, 7], [1, 2, 3, 0, 0, 0, 0], [1, 3, 3, 0, 0, 0, 0], [1, 3, 3, 0, 0, 0, 0], [1, 3, 3, 0, 0, 0, 0], [1, 3, 3, 0, 0, 0, 0], [1, 3, 3, 0, 0, 0, 0], [1, 3, 3, 0, 0, 0, 0], [1, 3, 3, 0, 0, 0, 0], [1, 3, 3, 0, 0, 0, 0], [1, 3, 3, 0, 0, 0, 0], [1, 3, 3, 0, 0, 0, 0], [1, 1, 4, 0, 3, 3, 6], [1, 1, 4, 0, 3, 3, 6], [1, 1, 4, 0, 3, 3, 6], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 2, 4, 0, 0, 0, 0], [1, 3, 4, 0, 0, 0, 0], [1, 3, 4, 0, 0, 0, 0], [1, 3, 4, 0, 0, 0, 0], [1, 3, 4, 0, 0, 0, 0], [1, 3, 4, 0, 0, 0, 0], [1, 3, 4, 0, 0, 0, 0], [1, 3, 4, 0, 0, 0, 0], [1, 3, 4, 0, 0, 0, 0], [1, 3, 4, 0, 0, 0, 0], [1, 3, 4, 0, 0, 0, 0], [1, 1, 5, 0, 2, 4, 7], [1, 1, 5, 0, 2, 4, 7], [1, 1, 5, 0, 2, 4, 7], [1, 2, 5, 0, 0, 0, 0], [1, 3, 5, 0, 0, 0, 0], [1, 3, 5, 0, 0, 0, 0], [1, 3, 5, 0, 0, 0, 0], [1, 3, 5, 0, 0, 0, 0], [1, 3, 5, 0, 0, 0, 0], [1, 3, 5, 0, 0, 0, 0], [1, 3, 5, 0, 0, 0, 0], [1, 3, 5, 0, 0, 0, 0], [1, 3, 5, 0, 0, 0, 0], [1, 1, 6, 0, 1, 5, 7], [1, 1, 6, 0, 1, 5, 7], [1, 1, 6, 0, 1, 5, 7], [1, 2, 6, 0, 0, 0, 0], [1, 2, 6, 0, 0, 0, 0], [1, 2, 6, 0, 0, 0, 0], [1, 2, 6, 0, 0, 0, 0], [1, 2, 6, 0, 0, 0, 0], [1, 2, 6, 0, 0, 0, 0], [1, 2, 6, 0, 0, 0, 0], [1, 2, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [1, 3, 6, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_toks = tokenizer(table=ex_tbl_df, queries=ex_text, max_length=300, padding=True)\n",
    "ex_toks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5916c6-3b0f-43ed-a3be-79a768eb8570",
   "metadata": {},
   "source": [
    "- `attention_mask`: table&text í† í°=1, padding=0\n",
    "\n",
    "- `token_type_ids`: TapasTokenizerì—ëŠ” í…Œì´ë¸” êµ¬ì¡°ë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•œ 7ê°œì˜ token type idê°€ ì¶”ê°€ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° idì— ëŒ€í•œ ì„¤ëª…ì€ ì•„ë˜ Tapas ê³µì‹ ë¬¸ì„œë¥¼ ë°œì·Œí•œ ë¶€ë¶„ì„ ì°¸ê³ í•´ì£¼ì„¸ìš”!\n",
    "\n",
    "    1. `segment_ids`: indicate **whether a token belongs to the question (0) or the table (1)**. 0 for special tokens and padding.\n",
    "    2. `column_ids`: indicate to **which column of the table** a token belongs (starting from 1). Is 0 for all question tokens, special tokens and padding.\n",
    "    3. `row_ids`: indicate to **which row of the table** a token belongs (starting from 1). Is 0 for all question tokens, special tokens and padding. Tokens of column headers are also 0.\n",
    "    4. `prev_labels`: indicate **whether a token was (part of) an answer to the previous question** (1) or not (0). Useful in a conversational setup (such as SQA dataset).\n",
    "    5. `column_ranks`: indicate the **rank of a table token relative to a column**, **if applicable**. For example, if you have a column \"number of movies\" with values 87, 53 and 69, then the column ranks of these tokens are 3, 1 and 2 respectively. 0 for all question tokens, special tokens and padding.\n",
    "    6. `inv_column_ranks`: indicate the **inverse rank** of a table token relative to a column, **if applicable**. For example, if you have a column \"number of movies\" with values 87, 53 and 69, then the inverse column ranks of these tokens are 1, 3 and 2 respectively. 0 for all question tokens, special tokens and padding.\n",
    "    7. `numeric_relations`: indicate numeric relations between the question and the tokens of the table. 0 for all question tokens, special tokens and padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f10ba2c-ab9a-4c13-947b-f46b919a9b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Nì„œìš¸íƒ€ì›Œì˜ ì¸µìˆ˜ëŠ” P0, P1, P2, EZ, T1, T2, T3, T5ë¡œ ì´ 8ê°œ ì¸µìœ¼ë¡œ ë˜ì–´ìˆë‹¤. PëŠ” í”Œë¼ìì˜ ì•½ìì´ë©° ì¶œì…êµ¬ì™€ ì•½ê°„ì˜ ìƒê°€ë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. EZëŠ” ìµìŠ¤í”„ë ˆìŠ¤ ì¡´ì˜ ì•½ìì´ë©° í°ìƒ‰ ê¸°ë‘¥ë¶€ë¶„ì„ ê°€ë¦¬í‚¨ë‹¤. TëŠ” íƒ€ì›Œì˜ ì•½ìì´ë©° ì „ë§ëŒ€ì™€ [UNK], ê·¸ë¦¬ê³  ì‹ë‹¹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì§€í•˜ 1ì¸µì—ì„œ ì§€ìƒ 5ì¸µê¹Œì§€ëŠ” ì„œìš¸íƒ€ì›Œ í”Œë¼ìì˜ ì‹œì„¤ì´ ìˆê³  5ì¸µë¶€í„° íƒ€ì›Œ 1ì¸µì—ì„œ íƒ€ì›Œ 5ì¸µê¹Œì§€ëŠ” Nì„œìš¸íƒ€ì›Œì˜ ì‹œì„¤ì´ ìˆë‹¤. ë‚¨ì‚° ì¼€ì´ë¸”ì¹´ë„ ìœ ëª…í•˜ë‹¤. [SEP] ì¸µìˆ˜ ì‹œì„¤ ë¹„ê³  [EMPTY] ì—”ê·¸ë¦´ / ê¸°ê³„ì‹¤ ì–‘ì‹ë‹¹'ì—”ê·¸ë¦´'ì´ë©° ì´ê³³ì—ì„œëŠ” ê°œì„±ê³¼ ì¸ì²œì˜ ê´€ì¸¡ë„ ê°€ëŠ¥í•˜ë‹¤... íƒ€ì›Œ 6ì¸µ Nì¹¼êµ­ìˆ˜, ì „ë§ëŒ€... íœ´ì „ì„ ê¹Œì§€ ê´€ì¸¡ ê°€ëŠ¥í•˜ë‹¤ íƒ€ì›Œ 5ì¸µ [EMPTY] ë””ì§€í„¸ ì „ë§ëŒ€ì™€ ìƒí–‰ ì—˜ë¦¬ë² ì´í„°ê°€ ìˆë‹¤. íƒ€ì›Œ 4ì¸µ ì „ë§ëŒ€, Ní¬í†  ìŠ¤íŠœë””ì˜¤, í•˜ëŠ˜ í™”ì¥ì‹¤, íˆ¬ì¸ì»¤í”¼ ì•„ë‚ ë¡œê·¸ ì „ë§ëŒ€ì™€ í•˜í–‰ ì—˜ë¦¬ë² ì´í„°ê°€ ìˆë‹¤. íƒ€ì›Œ 3ì¸µ [EMPTY] ì´ê³³ì—ì„œëŠ” ì„œìš¸ ì‹œë‚´ê¹Œì§€ë§Œ ë³´ì¸ë‹¤. íƒ€ì›Œ 2ì¸µ ë£¨í”„í…Œë¼ìŠ¤, ë” í”Œë ˆì´ìŠ¤ ë‹¤ì´ë‹ ë£¨í”„í…Œë¼ìŠ¤, ë” í”Œë ˆì´ìŠ¤ ë‹¤ì´ë‹ì´ ìˆë‹¤. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ex_toks['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6827fe8d-489e-4334-96ac-031d133e206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_info, len_info, query_ids, table_ids = tokenizer.get_idx_features_for_masking(table=ex_tbl_df, query=ex_text, max_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2daf7b3e-80da-4682-82d5-abca71fe4389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4, 5], [6, 7, 8], [9, 10], [11], [12, 13], [14], [15, 16], [17], [18, 19], [20], [21, 22], [23], [24, 25], [26], [27, 28], [29], [30, 31, 32], [33], [34, 35], [36, 37], [38, 39, 40, 41], [42], [43, 44], [45, 46], [47, 48, 49], [50, 51], [52, 53], [54, 55], [56, 57, 58, 59, 60], [61], [62, 63, 64], [65], [66, 67], [68, 69, 70], [71], [72, 73, 74], [75], [76], [77, 78], [79, 80], [81, 82, 83], [84, 85], [86], [87], [88], [89, 90], [91, 92, 93], [94, 95], [96], [97], [98, 99, 100], [101], [102, 103, 104, 105, 106], [107, 108, 109], [110, 111], [112, 113], [114, 115], [116, 117, 118], [119], [120, 121, 122], [123], [124, 125, 126, 127, 128], [129, 130, 131, 132, 133], [134, 135], [136, 137], [138], [139], [140, 141], [142, 143, 144], [145], [147, 148], [149], [150, 151], [152], [153, 154, 155, 156, 157, 158], [159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182], [183, 184, 185], [186, 187, 188, 189, 190], [191, 192, 193, 194, 195, 196, 197, 198, 199, 200], [201, 202, 203], [204], [205, 206, 207, 208, 209, 210, 211, 212, 213, 214], [215, 216, 217], [218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230], [231, 232, 233, 234, 235, 236, 237, 238, 239, 240], [241, 242, 243], [244], [245, 246, 247, 248, 249, 250, 251, 252, 253], [254, 255, 256], [257, 258, 259, 260, 261, 262, 263, 264], [265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276]]\n"
     ]
    }
   ],
   "source": [
    "print(idx_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85798b1c-c705-466d-9fb9-a6b8295910f2",
   "metadata": {},
   "source": [
    "ê° í•˜ìœ„ ë¦¬ìŠ¤íŠ¸ë“¤ì€ ë‹¨ì–´, cellì— ì†í•œ í† í°ë“¤ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´, query(text)ì˜ ì²«ë²ˆì§¸ ë‹¨ì–´(`[1, 2, 3, 4, 5]`)ëŠ” ì²«ë²ˆì§¸ í† í°ë¶€í„° ë‹¤ì„¯ë²ˆì§¸ í† í°ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì°¸ê³ ë¡œ `[CLS]` í† í°ì— í•´ë‹¹í•˜ëŠ” 0ë²ˆ ì¸ë±ìŠ¤ëŠ” ì´ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©°, ë§ˆì°¬ê°€ì§€ë¡œ textì™€ tableì„ ë¶„ë¦¬í•˜ëŠ” `[SEP]` í† í° ì—­ì‹œ ì œì™¸ëœ ìƒíƒœì…ë‹ˆë‹¤.\n",
    "\n",
    "ì¤‘ê°„ì— í† í°ì˜ ìœ„ì¹˜ ì¸ë±ìŠ¤ê°€ ë¹„ì–´ìˆëŠ” ì§€ì (ìœ„ ì˜ˆì‹œì—ì„œëŠ” 146ë²ˆ ì¸ë±ìŠ¤)ê°€ textì—ì„œ tableë¡œ ë„˜ì–´ê°€ëŠ” `[SEP]` í† í°ì˜ ìœ„ì¹˜ë¼ê³  ë³´ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "<br/>\n",
    "\n",
    "ë˜í•œ, ì•„ë˜ì™€ ê°™ì´ query(text)ì™€ tableì˜ ê¸¸ì´ ì •ë³´, ì¸ì½”ë”© ê²°ê³¼ê°€ í•¨ê»˜ ì œê³µë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8264ef4c-1951-4ac4-85f7-dab38b86cf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[145, 130]\n"
     ]
    }
   ],
   "source": [
    "print(len_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89a63daa-8f53-430c-a4bf-c401b7990a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 28750, 2256, 2667, 2079, 1688, 2113, 2259, 52, 2082, 16, 52, 2083, 16, 52, 2302, 16, 41, 2611, 16, 56, 2083, 16, 56, 2302, 16, 56, 2195, 16, 56, 2049, 2200, 1668, 28, 2019, 1688, 6233, 859, 2051, 2689, 2062, 18, 52, 2259, 16597, 2079, 9383, 2052, 2307, 18455, 2522, 4943, 2079, 6682, 2200, 3896, 2496, 2051, 2689, 2062, 18, 41, 2611, 2259, 24284, 1554, 2079, 9383, 2052, 2307, 12003, 9856, 12547, 2069, 16519, 18, 56, 2259, 8203, 2079, 9383, 2052, 2307, 14822, 2522, 1, 16, 3673, 5499, 6233, 3896, 2496, 2051, 1513, 2062, 18, 4670, 21, 2624, 27135, 5377, 25, 2624, 2299, 2118, 2259, 3671, 2256, 2667, 16597, 2079, 3953, 2052, 1513, 2088, 25, 2624, 3797, 8203, 21, 2624, 27135, 8203, 25, 2624, 2299, 2118, 2259, 50, 28750, 2256, 2667, 2079, 3953, 2052, 1513, 2062, 18, 12103, 15879, 2119, 4455, 2205, 2062, 18]\n"
     ]
    }
   ],
   "source": [
    "print(query_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0068b293-01b7-49a1-b583-fecc72ab27e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1688, 2113, 3953, 1187, 2088, 32000, 1423, 2029, 2388, 19, 5276, 2477, 6277, 2481, 11, 1423, 2029, 2388, 11, 1504, 2307, 4441, 27135, 2259, 5879, 2145, 4068, 2079, 6541, 2119, 3662, 2205, 2062, 18, 18, 18, 8203, 26, 2624, 50, 2600, 9473, 16, 14822, 18, 18, 18, 31099, 2299, 2118, 6541, 3662, 2205, 2062, 8203, 25, 2624, 32000, 5476, 14822, 2522, 1242, 2375, 10874, 2116, 1513, 2062, 18, 8203, 24, 2624, 14822, 16, 50, 2208, 2386, 9238, 16, 4573, 7047, 16, 1801, 3428, 20468, 16834, 14822, 2522, 1889, 2375, 10874, 2116, 1513, 2062, 18, 8203, 23, 2624, 32000, 4441, 27135, 2259, 3671, 6011, 2299, 3683, 4090, 18, 8203, 22, 2624, 19283, 2201, 5822, 16, 831, 18312, 5970, 2944, 19283, 2201, 5822, 16, 831, 18312, 5970, 2944, 2052, 1513, 2062, 18]\n"
     ]
    }
   ],
   "source": [
    "print(table_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192164d-d74a-4f54-9eee-3196b93e7cdb",
   "metadata": {},
   "source": [
    "### 1.2. `TableDataset` ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a708718-215e-4947-9aa9-40a9db40be7c",
   "metadata": {},
   "source": [
    "ìœ„ì—ì„œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•œ Table Tokenizerë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµì— í•„ìš”í•œ TableDatasetì„ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "099e822e-f74a-47ba-83a1-462326379bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset_utils.pyì— ìœ„ì¹˜í•  ê²ƒ\n",
    "\n",
    "def none_to_nan(name):\n",
    "    return \"nan\" if name == None else name\n",
    "\n",
    "def del_row_or_col(df, row_del_ratio, col_del_ratio):\n",
    "    \"\"\"nan ê°œìˆ˜ê°€ ì¼ì • ë¹„ìœ¨ ì´ìƒì´ë©´ í•´ë‹¹ column/row ì „ë¶€ ì‚­ì œí•˜ê¸° ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    n_r = df.shape[0]\n",
    "    n_c = df.shape[1]\n",
    "    \n",
    "    c_cand_del = []\n",
    "    for i_c in range(n_c):\n",
    "        n_col_nan = df.iloc[:,i_c].isnull().sum()\n",
    "        if n_col_nan > 0:\n",
    "            col_nan_ratio = n_col_nan/n_r\n",
    "            if col_nan_ratio > col_del_ratio:\n",
    "                # print(f\"col {i_c}({df.columns[i_c]}) insnull ratio: {col_nan_ratio}\")\n",
    "                c_cand_del.append(df.columns[i_c])\n",
    "    \n",
    "    r_cand_del = []\n",
    "    for i_r in range(n_r):\n",
    "        n_row_nan = df.iloc[i_r,:].isnull().sum()\n",
    "        if n_row_nan > 0:\n",
    "            row_nan_ratio = n_row_nan/n_c\n",
    "            if row_nan_ratio > row_del_ratio:\n",
    "                # print(f\"row {i_r}({df.index[i_r]}) insnull ratio: {row_nan_ratio}\")\n",
    "                r_cand_del.append(df.index[i_r])    \n",
    "    \n",
    "    # del nan col\n",
    "    df = df.drop(c_cand_del, axis=1)\n",
    "    # del nan row\n",
    "    df = df.drop(r_cand_del)\n",
    "    \n",
    "    # ë‹¤ ì§€ìš´ ë‹´ì—ëŠ” np.nan -> \"nan\"ìœ¼ë¡œ ë³€ê²½í•´ì„œ [EMPTY] í† í°ìœ¼ë¡œ ì¸ì‹ë˜ë„ë¡!\n",
    "    df = df.fillna('nan')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9352580-dbe9-42f0-a4bd-44ed27060ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import TapasTokenizer\n",
    "# from table_tokenizer import TableTokenizer\n",
    "\n",
    "\n",
    "class TableDataset(Dataset):\n",
    "    def __init__(self, data, args=None, tokenizer=None):\n",
    "        self.data = data\n",
    "        self.args = args\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, data_idx):\n",
    "        data_dict = self.data[data_idx]\n",
    "        text = data_dict['Description']\n",
    "        table = self.convert_list_to_df(data_dict['TBL'], self.args.row_del_ratio, self.args.col_del_ratio)\n",
    "        \n",
    "        real_text = self.tokenizer.query_truncate(text, self.args.max_query_len) ###max_query_len\n",
    "        \n",
    "        idx_info, len_info, _, _ = self.tokenizer.get_idx_features_for_masking(table=table, query=real_text, max_length=self.args.max_seq_len)\n",
    "        \n",
    "        inputs = self.tokenizer(table=table, queries=real_text, padding=True, max_length = self.args.max_seq_len, truncation=True)\n",
    "        # idx_info, len_info, _, _ = self.tokenizer.get_idx_features_for_masking(table=table, query=text)\n",
    "        # ## [[1, 2, 3, 4, 5], [6, 7, 8], [9, 10], [11], [12, 13], [14], [15, 16], ...]\n",
    "        \n",
    "        idx_info_copy = copy.deepcopy(idx_info)\n",
    "        \n",
    "        input_ids, labels = self.create_features_for_mlm(inputs['input_ids'], idx_info, len_info)\n",
    "        \n",
    "        return [input_ids, inputs['attention_mask'], inputs['token_type_ids'], labels, idx_info_copy]\n",
    "    \n",
    "    \n",
    "    def convert_list_to_df(self, table_list, row_del_ratio, col_del_ratio):\n",
    "        \"\"\"\n",
    "        ì´ ë©”ì†Œë“œëŠ” listë¡œ ì£¼ì–´ì§„ table inputì„ ë°›ì•„ pandas dataframe í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ë° ê°„ë‹¨í•œ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "        êµ¬ì²´ì ì¸ í”„ë¡œì„¸ìŠ¤ëŠ” ì£¼ì„ì„ ì°¸ê³ í•˜ì„¸ìš”!\n",
    "        \"\"\"\n",
    "        # 1. list -> dataframe\n",
    "        tbl_df = pd.DataFrame(table_list)\n",
    "        # 2. ì²«ë²ˆì§¸ í–‰ì€ column ì´ë¦„!\n",
    "        tbl_df = tbl_df.rename(columns=tbl_df.iloc[0])\n",
    "        # 3. column ì´ë¦„ìœ¼ë¡œ ì˜¬ë ¤ë†¨ìœ¼ë‹ˆ ì²«ë²ˆì§¸ í–‰ì€ ì§€ìš°ê¸°!\n",
    "        tbl_df = tbl_df.drop(tbl_df.index[0])\n",
    "        # 4. row index ì´ˆê¸°í™”!\n",
    "        tbl_df.reset_index(drop=True, inplace=True)\n",
    "        # 5. ë°ì´í„° íƒ€ì… ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì•¼ None -> \"None\"ìœ¼ë¡œ ë°”ë€Œê³ , tokenizing ê°€ëŠ¥!\n",
    "        tbl_df = tbl_df.astype('str')\n",
    "\n",
    "        # 6. row, column ë³„ë¡œ ëŒë©´ì„œ ë¹„ì–´ìˆëŠ” ê°’ì€ ëª¨ë‘ ê²°ì¸¡ì¹˜(np.nan)ë¡œ ë³€í™˜ -> ê²°ì¸¡ì¹˜ ë§ì€ í–‰, ì—´ì€ ì œê±°í•  ê²ƒì´ê¸° ë•Œë¬¸!\n",
    "        for row_index, row in tbl_df.iterrows():\n",
    "            for col_index, cell in enumerate(row):\n",
    "                if tbl_df.iloc[row_index, col_index].strip() == \"\" or tbl_df.iloc[row_index, col_index] == \"None\":\n",
    "                    tbl_df.iloc[row_index, col_index] = np.nan ###\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        # 7. ê²°ì¸¡ì¹˜ê°€ ë„ˆë¬´ ë§ì€ rowì™€ columnì€ ì œê±°!\n",
    "        tbl_df = del_row_or_col(tbl_df, row_del_ratio, col_del_ratio)\n",
    "\n",
    "        # 8. column ì´ë¦„ì´ Noneì¸ ê²½ìš° Nonetype error ë°©ì§€ë¥¼ ìœ„í•´ nanìœ¼ë¡œ rename!\n",
    "        tbl_df.columns = [none_to_nan(col) for col in list(tbl_df.columns)]\n",
    "\n",
    "        return tbl_df\n",
    "    \n",
    "    \n",
    "    def create_features_for_mlm(self, org_input_ids, idx_info, len_info):\n",
    "        \n",
    "        # masking ref: https://github.com/huggingface/transformers/blob/v4.11.3/src/transformers/data/data_collator.py#L924\n",
    "        \n",
    "        len_query_table = sum(len_info)\n",
    "    \n",
    "        num_to_predict = min(self.args.max_seq_len, max(1, int(round(len_query_table * self.args.mlm_prob))))\n",
    "\n",
    "        random.shuffle(idx_info) #ëœë¤ìœ¼ë¡œ ì„ê³  ì•ì—ì„œë¶€í„° ì°¨ë¡€ë¡œ maskingí•  í† í°ìˆ˜ ë§Œí¼ ì±„ì›€\n",
    "        ## [[1, 2, 3, 4, 5], [6, 7, 8], [9, 10], [11], [12, 13], [14], [15, 16], [17], ...] -> [[94, 95], [11], [62, 63, 64], ...]\n",
    "\n",
    "        masked_lms = []\n",
    "        covered_indexes = set()\n",
    "        for index_set in idx_info:\n",
    "            if len(masked_lms) >= num_to_predict:\n",
    "                break\n",
    "            # If adding a whole-word mask would exceed the maximum number of predictions, then just skip this candidate.\n",
    "            if len(masked_lms) + len(index_set) > num_to_predict:\n",
    "                continue\n",
    "            is_any_index_covered = False\n",
    "            for index in index_set:\n",
    "                if index in covered_indexes:\n",
    "                    is_any_index_covered = True\n",
    "                    break\n",
    "            if is_any_index_covered:\n",
    "                continue\n",
    "            for index in index_set:\n",
    "                covered_indexes.add(index)\n",
    "                masked_lms.append(index)\n",
    "\n",
    "        assert len(covered_indexes) == len(masked_lms)\n",
    "        mask_labels = [1 if i in covered_indexes else 0 for i in range(len_query_table + 2)] #+2: [CLS]ì™€ [SEP] ê°œìˆ˜ë„ í¬í•¨!!\n",
    "\n",
    "        for _ in range(self.args.max_seq_len - len(mask_labels)):\n",
    "            mask_labels.append(self.tokenizer.pad_token_id) # 0\n",
    "\n",
    "\n",
    "        # 1. labels\n",
    "        inputs = torch.Tensor(org_input_ids)\n",
    "        labels = inputs.clone()\n",
    "\n",
    "        masked_indices = torch.Tensor(mask_labels).bool()\n",
    "\n",
    "        labels[~masked_indices] = -100 #maskingëœ í† í°ì„ ì œì™¸í•˜ê³ ì„œëŠ” loss ì—°ì‚°ì—ì„œ ì œì™¸\n",
    "        \n",
    "        real_labels = labels.tolist()\n",
    "        \n",
    "        real_labels = [int(lab) for lab in real_labels]\n",
    "\n",
    "        # 2. input_ids\n",
    "        input_ids = inputs.tolist()\n",
    "        for mask_pos in masked_lms:\n",
    "            input_ids[mask_pos] = self.tokenizer.mask_token_id # 4\n",
    "            \n",
    "        input_ids = [int(inp) for inp in input_ids]\n",
    "\n",
    "        return input_ids, real_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1d6ae-398c-4265-8dc8-40e052b341b8",
   "metadata": {},
   "source": [
    "### 1.3. `table collate í•¨ìˆ˜` ë° `DatoLoader` ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43726a5b-c6ad-4a9c-b9fb-c0cb9a5b276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def table_collate_fn(batch):\n",
    "    \n",
    "    features = {\n",
    "        'input_ids': torch.LongTensor([sample[0] for sample in batch]),\n",
    "        'attention_mask': torch.LongTensor([sample[1] for sample in batch]),\n",
    "        'token_type_ids': torch.LongTensor([sample[2] for sample in batch]),\n",
    "        'labels': torch.LongTensor([sample[3] for sample in batch]),\n",
    "        'offsets': [sample[4] for sample in batch]\n",
    "    }\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c541fe71-e88b-40f1-a33b-bb31b5676f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = sample_data['data'][:170]\n",
    "valid_data = sample_data['data'][170:]\n",
    "\n",
    "train_dataset = TableDataset(train_data, args, tokenizer)\n",
    "valid_dataset = TableDataset(valid_data, args, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=table_collate_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=args.batch_size, collate_fn=table_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ded29-4506-4e29-a19d-188d26eb8a92",
   "metadata": {},
   "source": [
    "ì•„ë˜ cellì€ batch ì˜ˆì‹œë¥¼ ì¶œë ¥í•´ë³´ê¸° ìœ„í•´ ì„ ì–¸í•œ ê°€ìƒì˜ dataloaderì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‹¤ì œ í•™ìŠµ ë•ŒëŠ” ì‹¤í–‰í•˜ì§€ ì•Šìœ¼ì…”ë„ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8857997e-f070-4a8c-8148-f85d74bfa3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   2,  170, 1376,  ...,    0,    0,    0],\n",
      "        [   2,   14,  809,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]]), 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]]), 'offsets': [[[1], [2, 3], [4], [5], [6], [7], [8], [9, 10, 11], [12, 13, 14], [15], [16], [17, 18], [19, 20], [21], [22, 23], [24, 25], [26], [27, 28], [29], [31, 32, 33, 34, 35, 36, 37, 38, 39, 40], [41, 42, 43, 44, 45, 46, 47, 48, 49, 50], [51], [52, 53, 54, 55], [56], [57, 58, 59, 60, 61, 62, 63, 64], [65], [66, 67, 68, 69, 70, 71, 72, 73], [74], [75, 76, 77, 78, 79, 80, 81, 82], [83], [84, 85, 86, 87, 88, 89, 90, 91, 92], [93, 94], [95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112], [113], [114, 115], [116], [117, 118], [119, 120]], [[1], [2, 3, 4], [5, 6], [7, 8], [9], [10, 11, 12, 13], [14, 15], [16, 17], [18, 19], [20], [21], [23], [24], [25], [26], [27, 28], [29], [30, 31, 32, 33, 34, 35], [36], [37], [38, 39, 40]]]}\n"
     ]
    }
   ],
   "source": [
    "ex_dataloader = DataLoader(train_dataset, batch_size=2, collate_fn=table_collate_fn)\n",
    "\n",
    "batch_ex = next(iter(ex_dataloader))\n",
    "print(batch_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "469ae66e-6339-4d3d-8e78-f5e9dc7cd5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. input ids: \n",
      "tensor([    2,   170,  1376,  2320,  8347,   171,    12,     4,    30, 26384,\n",
      "         2054,  4704, 28495, 15869,  2041,    13,   793, 17591,  2615,  9296,\n",
      "         2170,     4,     4,     4,  6837,  2897,  9296,  3771, 28674,    18,\n",
      "            3,  1376,  2320,  8347,  2106,  2008,  7088,  4704, 28495, 15869,\n",
      "         2041,  1376,  2320,  8347,  2106,  2008,  7088,  4704, 28495, 15869,\n",
      "         2041,  3871,     4,     4,     4,     4,  4734, 10073,  1050,  2506,\n",
      "        16555,  2548,  4358, 22330, 17194,  4152, 14113, 13429,  2029,  2234,\n",
      "         3193,  2059,  2269,  2255, 12300,     4,     4,     4,     4,     4,\n",
      "            4,     4,     4, 28157, 27357,  1883,  2294,  2255, 11398,  1883,\n",
      "         2294,  2255,  5551,  6837,  2210,  4840,  2440,  3718,  2429,  3718,\n",
      "         2210,  4840,  2440,  3718,  2429,  4136,  2210,  4840,  2440,  3718,\n",
      "         2429,  3912,  2210,  3641,  7815,  2377,  3728,     4,     4,  4686,\n",
      "         4612,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n",
      "-----------------------------------------\n",
      "2. labels: \n",
      "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  4612,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  4249,  4840,  2440,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100, 12740,  1739, 22661, 14570,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100, 17591,  2615,  9296, 24569,  1883,\n",
      "         2294,  2255,  9296,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  4353,  3666,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100])\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"1. input ids: \\n{batch_ex['input_ids'][0]}\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"2. labels: \\n{batch_ex['labels'][0]}\")\n",
    "print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88975e-7b7a-4180-84d6-06e3c54cef7d",
   "metadata": {},
   "source": [
    "`input ids`ì—ì„œ maskingëœ tokenì€ masking ì¸ë±ìŠ¤ì¸ 4ë¥¼ ë¶€ì—¬ë°›ê³ , `labels`ì—ì„œëŠ” maksingëœ token ì™¸ ëª¨ë“  í† í°ë“¤ì´ ì „ë¶€ -100ì˜ ì¸ë±ìŠ¤ë¥¼ ë¶€ì—¬ë°›ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ MLM í•™ìŠµì„ ìœ„í•œ ë°ì´í„° êµ¬ì„±ì€ ëª¨ë‘ ë§ˆì³¤ìŠµë‹ˆë‹¤!\n",
    "\n",
    "ëª¨ë¸ë§ íŒŒíŠ¸ë¡œ ë„˜ì–´ê°€ë³´ì•„ìš”~!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eacec47-7b45-40bc-81be-0cba324a6cb8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73538c2-39a1-4d91-a371-8a31ed7d20aa",
   "metadata": {},
   "source": [
    "## 2. ëª¨ë¸ë§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc003a38-3f9a-4811-86eb-01b2f502effa",
   "metadata": {},
   "source": [
    "TapasëŠ” embeddingì„ ì œì™¸í•˜ê³ ì„œ BERTì™€ ë™ì¼í•œ êµ¬ì¡°ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì½”ë“œ ì—­ì‹œ BERT êµ¬í˜„ì²´ì™€ ìƒë‹¹íˆ ìœ ì‚¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ, huggingfaceì˜ `BertModel` ê³„ì—´ ì†ŒìŠ¤ì½”ë“œë¥¼ì„ ì ‘í•´ë³´ì‹  ë¶„ë“¤ì´ë¼ë©´ ìµìˆ™í•˜ì‹¤ ê²ë‹ˆë‹¤.\n",
    "\n",
    "Tapasì— MLMì„ ì¶”ê°€í•œ êµ¬ì¡°ëŠ” `TapasForMaskedLM`ì„ í†µí•´ ì†ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ ì „ì— ëª¨ë¸ì˜ ì •ë³´ë¥¼ ë‹´ì€ `TapasConfig`ë¥¼ í˜¸ì¶œí•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e63dda-4c4c-4420-8de1-c8e26c153d99",
   "metadata": {},
   "source": [
    "### 2.1. `TapasConfig` ìˆ˜ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc14135-797d-4982-8c28-d750144ef355",
   "metadata": {},
   "source": [
    "> _\"ê·¸ëƒ¥ ëª¨ë¸ ê°€ì ¸ë‹¤ ì“°ë©´ ëœë‹¤ë©´ì„œìš”. ì™œ configë¥¼ ìˆ˜ì •í•˜ëŠ”ê±°ì£ ?\"_\n",
    "\n",
    "TapasConfigëŠ” ê¸°ì¤€ ì–¸ì–´ê°€ ì˜ì–´ë¡œ ë§ì¶°ì ¸ ìˆì–´ì„œ ëª¨ë¸ ì´ˆë°˜ Embedding Layerë¥¼ ê´€í• í•˜ëŠ” `vocab_size`ê°€ `bert-base-uncased`ì˜ vocab ê°œìˆ˜ì¸ 30522ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fd8d900-4c42-464f-ac93-ae28d204fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TapasConfig\n",
    "config = TapasConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "824b5e49-0e8f-4d43-bd76-996664a78df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f08f3-50d0-451a-87c3-18a137ec4795",
   "metadata": {},
   "source": [
    "ìš°ë¦¬ëŠ” í•œêµ­ì–´ table mrcë¥¼ ìœ„í•œ tapas ëª¨ë¸ì„ êµ¬ì¶•í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì—, ì¼ì „ì— `TableTokenizer`ë¥¼ ë¡œë“œí•  ë•Œ ì‚¬ìš©í–ˆë˜ `klue/bert-base`ì— ë§ëŠ” vocab_sizeë¥¼ ìƒˆë¡œ ì •ì˜í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "`TapasTokenizer`ì—ëŠ” special tokenì¸ `[EMPTY]`ê°€ ì¶”ê°€ë¡œ ë¶€ì—¬ë˜ì–´ ìˆëŠ” ê´€ê³„ë¡œ, ê¸°ì¡´ `klue/bert-base`ì˜ vocab size(32000)ì—ì„œ 1ì„ ì¶”ê°€í•œ 32001ë¡œ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5a5cae4-a9e4-4206-885f-da2c1265535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.vocab_size = 32001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "363bc474-1fae-452a-8304-183d3fbc6523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TapasConfig {\n",
       "  \"aggregation_labels\": null,\n",
       "  \"aggregation_loss_weight\": 1.0,\n",
       "  \"aggregation_temperature\": 1.0,\n",
       "  \"allow_empty_column_selection\": false,\n",
       "  \"answer_loss_cutoff\": null,\n",
       "  \"answer_loss_importance\": 1.0,\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"average_approximation_function\": \"ratio\",\n",
       "  \"average_logits_per_cell\": false,\n",
       "  \"cell_selection_preference\": null,\n",
       "  \"disable_per_token_loss\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"huber_loss_delta\": null,\n",
       "  \"init_cell_selection_weights_to_zero\": false,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_num_columns\": 32,\n",
       "  \"max_num_rows\": 64,\n",
       "  \"max_position_embeddings\": 1024,\n",
       "  \"model_type\": \"tapas\",\n",
       "  \"no_aggregation_label_index\": null,\n",
       "  \"num_aggregation_labels\": 0,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"positive_label_weight\": 10.0,\n",
       "  \"reset_position_index_per_cell\": true,\n",
       "  \"select_one_column\": true,\n",
       "  \"transformers_version\": \"4.11.3\",\n",
       "  \"type_vocab_sizes\": [\n",
       "    3,\n",
       "    256,\n",
       "    256,\n",
       "    2,\n",
       "    256,\n",
       "    256,\n",
       "    10\n",
       "  ],\n",
       "  \"use_answer_as_supervision\": null,\n",
       "  \"use_gumbel_for_aggregation\": false,\n",
       "  \"use_gumbel_for_cells\": false,\n",
       "  \"use_normalized_answer_loss\": false,\n",
       "  \"vocab_size\": 32001\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c698c-b599-4749-855a-077d8432bef8",
   "metadata": {},
   "source": [
    "ë§¨ ì•„ë˜ `vocab_size`ë¥¼ ë³´ë‹ˆ ì˜ ìˆ˜ì •ì´ ë˜ì—ˆë„¤ìš”.\n",
    "\n",
    "- ë°”ë¡œ ì•„ë˜ `2.2. TapasForMaskedLM ì†Œí™˜`ì—ì„œ model êµ¬ì¡°ë¥¼ ì¶œë ¥í•œ ì…€ì„ ë³´ë©´ Word Embedding layerì˜ input ì°¨ì› ì—­ì‹œ 32001ë¡œ ë°”ë€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "ì´ì œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µì‹œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616880f-87ae-4567-bbd0-bb5dc8969b29",
   "metadata": {},
   "source": [
    "### 2.2. `TapasForMaskedLM` ì†Œí™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05532f39-c03b-4ff4-9a77-ff9c4bd27be3",
   "metadata": {},
   "source": [
    "ìœ„ì—ì„œ ìˆ˜ì •í•œ Tapas configë¥¼ ì…ë ¥ ë³€ìˆ˜ë¡œ ë„£ì–´ ë¯¸ë¦¬ ì˜ êµ¬ì¶•ëœ Tapas MLM ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4bd9992-7b1a-4088-af62-3c2e6f5abfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TapasForMaskedLM\n",
    "\n",
    "model = TapasForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d94455eb-402f-49b8-907e-23f9c0bcbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model).to(args.device)\n",
    "    \n",
    "else:\n",
    "    model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39827412-a682-43ea-b129-2243da37a437",
   "metadata": {},
   "source": [
    "ì•ì„œ ë§ì”€ë“œë ¸ ë“¯ì´ MLMì€ ë§¨ ë§ˆì§€ë§‰ classifierì—ì„œ vocab size ë§Œí¼ì˜ output label ìˆ˜ë¥¼ ê°€ì§€ê¸° ë•Œë¬¸ì— ë°œìƒë˜ëŠ” íŒŒë¼ë¯¸í„° ìˆ˜ê°€ êµ‰ì¥íˆ í½ë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ, ë©”ëª¨ë¦¬ ìš©ëŸ‰ì´ í° single GPUë‚˜ ì—¬ëŸ¬ ê°œì˜ GPUê°€ í• ë‹¹ëœ ì„œë²„ê°€ ì•„ë‹Œ ì´ìƒ, í•™ìŠµì„ ìˆ˜í–‰í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì œ ê²½ìš°ì—ëŠ” multi GPUì¸ `Titan-RTX-4way`(24GB*4)ë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "multi-gpuë¥¼ í™œìš©í•˜ëŠ” ê²½ìš°, ë¶„ì‚° í•™ìŠµì„ ìœ„í•´ ëª¨ë¸ì€ DataParallelì´ë¼ëŠ” ê°ì²´ì— ë¬¶ì´ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ model êµ¬ì¡°ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80ef4702-c77e-43da-b9b8-19505c046440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): TapasForMaskedLM(\n",
       "    (tapas): TapasModel(\n",
       "      (embeddings): TapasEmbeddings(\n",
       "        (word_embeddings): Embedding(32001, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(1024, 768)\n",
       "        (token_type_embeddings_0): Embedding(3, 768)\n",
       "        (token_type_embeddings_1): Embedding(256, 768)\n",
       "        (token_type_embeddings_2): Embedding(256, 768)\n",
       "        (token_type_embeddings_3): Embedding(2, 768)\n",
       "        (token_type_embeddings_4): Embedding(256, 768)\n",
       "        (token_type_embeddings_5): Embedding(256, 768)\n",
       "        (token_type_embeddings_6): Embedding(10, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): TapasEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): TapasLayer(\n",
       "            (attention): TapasAttention(\n",
       "              (self): TapasSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): TapasSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): TapasIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): TapasOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): TapasOnlyMLMHead(\n",
       "      (predictions): TapasLMPredictionHead(\n",
       "        (transform): TapasPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=32001, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd82d1-2868-4c08-baa0-2e7e2c078bcc",
   "metadata": {},
   "source": [
    "ìš°ë¦¬ê°€ ì‚¬ì „í•™ìŠµì„ ì˜ ìˆ˜í–‰í•˜ê³ ì„œ í’€ì–´ì•¼ í•  downstream taskëŠ” ê²°êµ­ Table Question-Answeringì…ë‹ˆë‹¤.\n",
    "\n",
    "Fine-tuning(Table QA í•™ìŠµ)ì„ í•  ë•Œ, Pre-trainingì— ì“°ì˜€ë˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ê°€ ë‹¤ í•„ìš”í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "- queryì™€ table ê° í† í°ë“¤ì˜ Embeddingì„ ìˆ˜í–‰í•˜ê³  representationì„ ìƒì„±í•˜ëŠ” `TapasModel`ë§Œì´ fine-tuning ëª¨ë¸ êµ¬ì¶•ì— í™œìš©ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2913dc54-c9c6-437d-aff4-439ff276c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ cellì„ ì‹¤í–‰í•˜ì‹œë©´ TapasModelì˜ êµ¬ì¡°ë§Œ ë”°ë¡œ í™•ì¸í•  ìˆ˜ ìˆì”ë‹ˆë‹¤.\n",
    "model.module.tapas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9882f7-f2f2-4af7-b639-3704fa23b131",
   "metadata": {},
   "source": [
    "ë”°ë¼ì„œ, ëª¨ë¸ í•™ìŠµ ê³¼ì • ì¤‘ì— ì €ì¥í•  íŒŒë¼ë¯¸í„°ëŠ” `torch.save(model.module.tapas.state_dict(), output_dir)`ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.\n",
    "\n",
    "- ì´ì— ëŒ€í•œ ì½”ë“œëŠ” ì•„ë˜ `3. í•™ìŠµ` íŒŒíŠ¸ì˜ `train` í•¨ìˆ˜ì—ì„œ (*) ë¶€ë¶„ì„ ë³´ì‹œë©´ ë©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bca5f2-ac4b-4441-a0da-bc5e83cb3ddf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d563dc-5264-46a7-aeb8-67bb4f7345a2",
   "metadata": {},
   "source": [
    "## 3. í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171232c-8b0f-446c-880c-63c8d4f4df90",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì„ ì •ì˜í–ˆìœ¼ë‹ˆ, ì´ì œ í•™ìŠµê³¼ í‰ê°€ì— í•„ìš”í•œ train, evaluate í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³ , ì‹¤ì œ í•™ìŠµì„ ìˆ˜í–‰í•  ë‹¨ê³„ì…ë‹ˆë‹¤.\n",
    "\n",
    "í•™ìŠµ ê³¼ì • ì¤‘ ê¸°ë¡ë˜ëŠ” logëŠ” `wandb` í”Œë«í¼ì—ì„œ ì‹œê°í™” ë˜ë„ë¡ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59688b40-28b0-4a88-9624-b89fdd61bdc6",
   "metadata": {},
   "source": [
    "### 3.1. í•™ìŠµ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4742e2-c351-40f6-bd4c-f822c04a124d",
   "metadata": {},
   "source": [
    "#### 3.1.1. train, eval í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d230fe5c-990d-4720-9714-8535f5f1b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, train_dataloader, valid_dataloader, optimizer, lr_scheduler):\n",
    "    \n",
    "    global_step = 0\n",
    "    best_loss = 100\n",
    "\n",
    "    wandb.init(\n",
    "        project=args.wandb_project,\n",
    "        name=args.wandb_name,\n",
    "        entity=args.wandb_entity\n",
    "    )\n",
    "    \n",
    "    wandb.config.update(\n",
    "        {\n",
    "            \"epochs\": args.epoch,\n",
    "            \"batch_size\": args.batch_size,\n",
    "            \"learning_rate\": args.learning_rate,\n",
    "        }\n",
    "    )\n",
    "    wandb.watch(model, log=\"all\")\n",
    "\n",
    "    for epoch in tqdm(range(1, args.epoch+1)):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        losses = 0\n",
    "        for batch_idx, batch in enumerate(train_dataloader):\n",
    "            \n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(args.device),\n",
    "                'attention_mask': batch['attention_mask'].to(args.device),\n",
    "                'token_type_ids': batch['token_type_ids'].to(args.device),\n",
    "                'labels': batch['labels'].to(args.device),\n",
    "            }\n",
    "            \n",
    "            output = model(**inputs)\n",
    "\n",
    "            loss = output.loss.mean()\n",
    "            losses += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            \n",
    "            if global_step % args.eval_step == 0:\n",
    "                \n",
    "                eval_loss = evaluate(\n",
    "                    args, model,\n",
    "                    valid_dataloader\n",
    "                )\n",
    "                \n",
    "                # train logging\n",
    "                wandb.log({\n",
    "                    'train_mlm_loss': loss.item(),\n",
    "                    'eval_mlm_loss': eval_loss\n",
    "                })\n",
    "                \n",
    "\n",
    "                if eval_loss < best_loss:\n",
    "                    best_loss = eval_loss\n",
    "                    output_dir = os.path.join(args.output_dir, \"best_tapas_model.pt\")\n",
    "                    \n",
    "                    # (*) ëª¨ë¸ ì €ì¥\n",
    "                    # torch.save(model.tapas.state_dict(), output_dir) #single GPU\n",
    "                    torch.save(model.module.tapas.state_dict(), output_dir) # multi GPU\n",
    "\n",
    "        \n",
    "        epoch_eval_loss = evaluate(args, model,valid_dataloader)\n",
    "        \n",
    "        print(f\"[Epoch{epoch}] Train mlm loss: {losses/len(train_dataloader)}, Eval mlm loss: {epoch_eval_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de9df6e4-3cd0-423c-a5dc-99d9913ada7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, model, eval_dataloader):\n",
    "    \n",
    "    model.eval()    # close drop out, batch normalization\n",
    "\n",
    "    eval_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                'input_ids': batch['input_ids'].to(args.device),\n",
    "                'attention_mask': batch['attention_mask'].to(args.device),\n",
    "                'token_type_ids': batch['token_type_ids'].to(args.device),\n",
    "                'labels': batch['labels'].to(args.device),\n",
    "            }\n",
    "            \n",
    "            output = model(**inputs)\n",
    "\n",
    "            loss = output.loss.mean()\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "    return eval_loss/len(eval_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954ab6d-b9c7-4846-9548-08c3312480cf",
   "metadata": {},
   "source": [
    "#### 3.1.2. optimizer, lr_scheduler ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "837f5645-cdd6-4292-a72f-f75514e60479",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in model.named_parameters()\n",
    "            if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p\n",
    "            for n, p in model.named_parameters()\n",
    "            if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": args.weight_decay,\n",
    "    },\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)\n",
    "\n",
    "train_step = args.epoch * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "        name=args.lr_scheduler_type,\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=args.num_warmup_steps,\n",
    "        num_training_steps=train_step,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845dabd1-0621-4ba6-8a80-014ef99ec1b2",
   "metadata": {},
   "source": [
    "### 3.2. Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10ff5145-5314-4d81-b443-b031ce11d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ë¥¼ ë¬´ì‹œí•˜ê³  ìˆ¨ê¸°ê±°ë‚˜\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b673acb-2e9e-4c15-a135-cf5cab49a830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/go60/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/codes/lab602/tablemrc/wandb/run-20220728_080052-32o4lkqn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/yookyungkho/Table%20Pretraining/runs/32o4lkqn\" target=\"_blank\">tapas-base-mlm-clean</a></strong> to <a href=\"https://wandb.ai/yookyungkho/Table%20Pretraining\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                  | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                                                                 | 1/5 [00:27<01:49, 27.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch1] Train mlm loss: 9.664233554493297, Eval mlm loss: 8.657608985900879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                         | 2/5 [00:51<01:15, 25.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch2] Train mlm loss: 8.181182167746805, Eval mlm loss: 7.921424865722656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                | 3/5 [01:13<00:47, 23.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch3] Train mlm loss: 7.727213035930287, Eval mlm loss: 7.8767523765563965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                        | 4/5 [01:37<00:23, 23.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch4] Train mlm loss: 7.543686736713756, Eval mlm loss: 7.736621379852295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:59<00:00, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch5] Train mlm loss: 7.48064695705067, Eval mlm loss: 7.823406219482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(args, model, train_dataloader, valid_dataloader, optimizer, lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a88a3b-2c4c-4d52-af9e-2a3e3ed2250c",
   "metadata": {},
   "source": [
    "í•™ìŠµ ì¤‘ê°„ì— ì¶œë ¥ëœ ê²½ê³  ë©”ì„¸ì§€ëŠ” DDPê°€ ì•„ë‹Œ DPë¥¼ ì‚¬ìš©í•´ì„œ ê·¸ë ‡ìŠµë‹ˆë‹¤.([ê´€ë ¨ link](https://github.com/huggingface/transformers/issues/14128))\n",
    "\n",
    "í–¥í›„ DDP ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•  ì˜ˆì •ì´ë‹ˆ ì°¸ê³ í•´ì£¼ì„¸ìš”!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
